
def normalize_date(date):
    import re
    months = {'январь':'01','февраль':'02','март':'03','апрель':'04','май':'05','июнь':'06','июль':'07','август':'08','сентябрь':'09','октябрь':'10','ноябрь':'11','декабрь':'12'}
    month = months[re.findall('\- (.*?) ', date)[0].lower()]
    day = re.findall(' [(0-9)]*?[snrt]', date)[0]
    day = day[:len(day)-1]
    year = re.findall(', (.*?) ', date)[0]
    return day+'.'+month+'.'+year


class Article():
    def __init__(self, raw, parsed = False):
        import pymorphy2
        m = pymorphy2.MorphAnalyzer()
        from nltk import word_tokenize
        if parsed == False:
            import re
            import urllib.request
            self.author = 'NoName'
            self.link = re.findall('<a href="(.*?)"', raw, flags=re.DOTALL)[0]
            print ('URL: ', self.link)
            self.title = re.findall('rel="bookmark" title="(.*?)"', raw, flags=re.DOTALL)[0]
            self.date = re.findall('"post-date">(.*?)<a', raw, flags=re.DOTALL)[0]
            self.date = normalize_date(self.date)
            self.page = urllib.request.Request(self.link)
            self.page = urllib.request.urlopen(self.page)
            self.page = self.page.read().decode('utf-8')
            self.topic = re.findall('В рубрике.*?<.*?>(.*?)<', self.page, flags=re.DOTALL)[0]
            self.text = re.findall('блока фотографий-->(.*?)<b>Понравилась статья', self.page, flags=re.DOTALL)[0]
            self.text = re.sub('<.*?>', '', self.text)
            self.text = re.sub('&.*?;', '', self.text)
        else:
            import re
            self.author = re.findall('@au .*?\n', raw)[0]
            self.title = re.findall('@ti .*?\n', raw)[0]
            self.link = re.findall('@url .*?\n', raw)[0]
            self.topic = re.findall('@topic .*?\n', raw)[0]
            self.date = re.findall('@da .*?\n', raw)[0]
            self.text = re.findall('@url.*?\n(.*)', raw, flags=re.DOTALL)[0]
        self.bol = ([m.parse(w)[0].normal_form for w in word_tokenize(self.text) if m.parse(w)[0].tag.POS not in ['PREP', 'CONJ', 'PRCL']])

    def save(self):
        file = open('corpus/' + self.title + '.txt', 'w', encoding='utf-8')
        out = '@au ' + self.author + '\n@ti ' + self.title + '\n@da ' + self.date + '\n@topic ' + self.topic + '\n@url ' + self.link + '\n' + self.text
        file.write(out)
        file.close()

class Corpus():
    def __init__(self):
        self.articles = []

    def add_article(self, article):
        self.articles.append(article)

    def create(self, size):
        import urllib.request
        import re
        import os
        file = urllib.request.Request('http://desnyanka.ru/')
        file = urllib.request.urlopen(file)
        filetext = file.read().decode('utf-8')
        months = re.findall('<a href=\'(.*?)\'', re.findall('Архивы.*?<ul>.*?<\/ul>', filetext, flags=re.DOTALL)[0], flags=re.DOTALL)
        #links = re.findall('Архивы.*?<ul>.*?<\/ul>', filetext, flags=re.DOTALL)[0]
        print (months)
        os.makedirs('.\corpus', exist_ok=True)
        number = 0
        for i in range(len(months)):
            if number >= size: break
            cur_month = urllib.request.Request(months[i])
            cur_month = urllib.request.urlopen(cur_month)
            cur_month = cur_month.read().decode('utf-8')
            cur_articles = re.findall('<div class="post-meta".*?<!', cur_month, flags=re.DOTALL)
            #for i in cur_articles:
            #    print(i)
            for art in cur_articles:
                try:
                    if number >= size: break
                    #print (art)
                    new = Article(art)
                    new.save()
                    self.articles.append(new)
                    number += 1
                except:
                    pass

    def open(self):
        import os
        for root, dirs, files in os.walk('.\corpus'):
            for file in files:
                if file[len(file)-3: len(file)] == 'txt':
                    newf = open('.\corpus\\'+file, 'r', encoding='utf-8')
                    new = newf.read()
                    self.articles.append(Article(new, parsed=True))
                    newf.close()
                else:
                    print ('empty')


    def get_matrix(self, save = True):
        import collections as cl
        import pymystem3
        import pymorphy2
        m = pymorphy2.MorphAnalyzer()
        from nltk import word_tokenize
        #ms = pymystem3.Mystem()
        corp = [a.text for a in self.articles]
        banlist = [' ', ',', '\ufeff', '.', ':', ';', '?', '!']
        mtx = cl.defaultdict()
        #print (len(corpus))
        #print (corpus[:10])
        for num in range(len(corp)):
            print ('aa')
            print (corp[num][:15])
            text = ([m.parse(w)[0].normal_form for w in word_tokenize(corp[num]) if m.parse(w)[0].tag.POS not in ['PREP', 'CONJ', 'PRCL']])
            #test = corp[num]
            #text = ms.lemmatize(corp[num])
            #rint('lemmatized')
            for word in text:
                if word not in banlist and '\n' not in word:
                    if word not in mtx:
                        mtx[word] = []
                    if str(num) not in mtx[word]:
                        mtx[word].append(str(num))
        if save == True:
            file = open('ii_list.txt', 'w', encoding='utf-8')
            out = '\n'.join([w + ' - ' + ', '.join(mtx[w]) for w in mtx])
            file.write(out)
            file.close()
        return mtx

    def compute_K(self, dl, avdl):
        k1 = 2.0
        b = 0.75
        return k1 * ((1 - b) + b * (float(dl) / float(avdl)))

    def score_BM25(self, n, fq, N, dl, avdl):
        #$f(q_i,D)$ - частота слова (TF) $q_i$ в документе $D$
        #$|D|$ - - длина документа (количество слов в нём)
        #avdl — средняя длина документа в коллекции
        # $N$ - общее количество документов в коллекции
        #$n(q_i)$ — количество документов, содержащих $q_i$
        from math import log
        k1 = 2.0
        b = 0.75
        K = self.compute_K(dl, avdl)
        IDF = log((N - n + 0.5) / (n + 0.5))
        frac = ((k1 + 1) * fq) / (K + fq)
        return IDF * frac




    def request(self, req):
        import os
        for i in range (0, 1):
            try:
                file = open ('ii_list.txt', 'w', encoding='utf-8')
            except:
                self.get_matrix()
                file = open ('ii_list.txt', 'w', encoding='utf-8')
        ii_list_t = file.read()
        file.close()
        ii_list = {}
        req = req.split()
        #
        req = [w.strip('!?.,:;-"') for w in req]
        for root, dirs, files in os.walk('.\corpus'):
            #
            N = len(files)
        avdl = sum([len(a.text) for a in self.articles])
        for l in ii_list_t.split('\n'):
            new = l.split(' - ')
            ii_list[new[0]] = new[1]


'''   def make_ii_list(self):
        import pymorphy2
        import pymystem3
        mst = pymystem3.Mystem()
        m = pymorphy2.MorphAnalyzer()
        ii_list = {}
        for a in self.articles:
            lem_text = mst.lemmatize(a.text)'''




#import os
#os.makedirs('.\corpus', exist_ok=True)
#file = open('.\corpus\dummy.txt','w', encoding='utf-8')
#file.write('helloworld')
c = Corpus()
c.open()
#c.get_matrix()
#print(len(c.articles))
#for i in c.articles:
#    print (i.date)
#c.create(100)
